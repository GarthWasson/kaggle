{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "sess = tf.InteractiveSession()\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import urllib\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import *\n",
    "from pyspark import SparkConf,SparkContext\n",
    "\n",
    "from pyspark.sql.functions import UserDefinedFunction\n",
    "from pyspark.sql.types import StringType ,DoubleType ,BooleanType, IntegerType\n",
    "from pyspark.sql.functions import udf ,col ,upper, avg\n",
    "\n",
    "from pyspark.ml.regression import RandomForestRegressor\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "from pyspark.ml.classification import GBTClassifier\n",
    "from pyspark.ml.regression import GBTRegressor ,LinearRegression ,GeneralizedLinearRegression\n",
    "from pyspark.ml.feature import StringIndexer, VectorIndexer\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml.linalg import Vectors \n",
    "from pyspark.ml.linalg import VectorUDT\n",
    "\n",
    "from pyspark.ml.classification import MultilayerPerceptronClassifier\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "from pyspark.ml.clustering import KMeans\n",
    "\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import GBTClassifier\n",
    "from pyspark.ml.regression import GBTRegressor ,LinearRegression ,GeneralizedLinearRegression\n",
    "\n",
    "\n",
    "from pyspark.ml.feature import StringIndexer, VectorIndexer\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.mllib.evaluation import RegressionMetrics\n",
    "\n",
    "from pyspark.ml.feature import PCA\n",
    "\n",
    "from pyspark.ml.linalg import Vectors \n",
    "from pyspark.ml.linalg import VectorUDT\n",
    "from pyspark.ml.regression import DecisionTreeRegressor\n",
    "from pyspark.ml.feature import VectorAssembler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sc=SparkContext()\n",
    "sqlContext=SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#For gpu accelerated NN training:\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Dropout\n",
    "from keras.layers import Merge\n",
    "from keras.regularizers import l2\n",
    "from keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import log_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.69234696709\n",
      "0.691346099002\n",
      "0.689943758458\n",
      "0.69314718056\n"
     ]
    }
   ],
   "source": [
    "print log_loss([0]*520  + [1]*480,[[.52,.48]]*1000)\n",
    "print log_loss([0]*530  + [1]*470,[[.53,.47]]*1000)\n",
    "print log_loss([0]*540  + [1]*460,[[.54,.46]]*1000)\n",
    "\n",
    "print log_loss([0]*520  + [1]*480,[[.5,.5]]*1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'numpy.version' from '/usr/local/lib/python2.7/dist-packages/numpy/version.pyc'>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check that nvida drivers are working:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Feb  6 12:09:29 2017       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 367.57                 Driver Version: 367.57                    |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  GeForce GTX 860M    Off  | 0000:01:00.0     Off |                  N/A |\r\n",
      "| N/A   49C    P0    N/A /  N/A |   3844MiB /  4043MiB |     14%      Default |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                       GPU Memory |\r\n",
      "|  GPU       PID  Type  Process name                               Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|    0      1109    G   /usr/lib/xorg/Xorg                             306MiB |\r\n",
      "|    0      2011    G   compiz                                         142MiB |\r\n",
      "|    0      2625    G   ...s-passed-by-fd --v8-snapshot-passed-by-fd    89MiB |\r\n",
      "|    0      7973    C   /usr/bin/python                                 55MiB |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of training set:\n",
      "136573\n",
      "length of tournament set:\n",
      "93498\n"
     ]
    }
   ],
   "source": [
    "numerai_train_df     = sqlContext.read.option(\"header\",\"true\").csv('file:///home/garth/Downloads/numerai20170130/numerai_training_data.csv',inferSchema='true')\n",
    "numerai_tournament_df= sqlContext.read.option(\"header\",\"true\").csv('file:///home/garth/Downloads/numerai20170130/numerai_tournament_data.csv',inferSchema='true')\n",
    "\n",
    "print \"length of training set:\"\n",
    "print (numerai_train_df.count())\n",
    "print \"length of tournament set:\"\n",
    "print (numerai_tournament_df.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#numerai_train_df.show(1,False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert input for use in ml lib algos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_df=numerai_train_df.rdd.map(lambda x: (float(x.target),Vectors.dense([\n",
    "                x.feature1\n",
    "                ,x.feature2\n",
    "                ,x.feature3\n",
    "                ,x.feature4\n",
    "                ,x.feature5\n",
    "                ,x.feature6\n",
    "                ,x.feature7\n",
    "                ,x.feature8\n",
    "                ,x.feature9\n",
    "                ,x.feature10\n",
    "                ,x.feature11\n",
    "                ,x.feature12\n",
    "                ,x.feature13\n",
    "                ,x.feature14\n",
    "                ,x.feature15\n",
    "                ,x.feature16\n",
    "                ,x.feature17\n",
    "                ,x.feature18\n",
    "                ,x.feature19\n",
    "                ,x.feature20\n",
    "                ,x.feature21\n",
    "                ,x.feature22\n",
    "                ,x.feature23\n",
    "                ,x.feature24\n",
    "                ,x.feature25\n",
    "                ,x.feature26\n",
    "                ,x.feature27\n",
    "                ,x.feature28\n",
    "                ,x.feature29\n",
    "                ,x.feature30\n",
    "                ,x.feature31\n",
    "                ,x.feature32\n",
    "                ,x.feature33\n",
    "                ,x.feature34\n",
    "                ,x.feature35\n",
    "                ,x.feature36\n",
    "                ,x.feature37\n",
    "                ,x.feature38\n",
    "                ,x.feature39\n",
    "                ,x.feature40\n",
    "                ,x.feature41\n",
    "                ,x.feature42\n",
    "                ,x.feature43\n",
    "                ,x.feature44\n",
    "                ,x.feature45\n",
    "                ,x.feature46\n",
    "                ,x.feature47\n",
    "                ,x.feature48\n",
    "                ,x.feature49\n",
    "                ,x.feature50\n",
    "                ]))).toDF([\"label\",\"features\"])\n",
    "\n",
    "tournament_df=numerai_tournament_df.rdd.map(lambda x: (x.t_id,Vectors.dense([\n",
    "                x.feature1\n",
    "                ,x.feature2\n",
    "                ,x.feature3\n",
    "                ,x.feature4\n",
    "                ,x.feature5\n",
    "                ,x.feature6\n",
    "                ,x.feature7\n",
    "                ,x.feature8\n",
    "                ,x.feature9\n",
    "                ,x.feature10\n",
    "                ,x.feature11\n",
    "                ,x.feature12\n",
    "                ,x.feature13\n",
    "                ,x.feature14\n",
    "                ,x.feature15\n",
    "                ,x.feature16\n",
    "                ,x.feature17\n",
    "                ,x.feature18\n",
    "                ,x.feature19\n",
    "                ,x.feature20\n",
    "                ,x.feature21\n",
    "                ,x.feature22\n",
    "                ,x.feature23\n",
    "                ,x.feature24\n",
    "                ,x.feature25\n",
    "                ,x.feature26\n",
    "                ,x.feature27\n",
    "                ,x.feature28\n",
    "                ,x.feature29\n",
    "                ,x.feature30\n",
    "                ,x.feature31\n",
    "                ,x.feature32\n",
    "                ,x.feature33\n",
    "                ,x.feature34\n",
    "                ,x.feature35\n",
    "                ,x.feature36\n",
    "                ,x.feature37\n",
    "                ,x.feature38\n",
    "                ,x.feature39\n",
    "                ,x.feature40\n",
    "                ,x.feature41\n",
    "                ,x.feature42\n",
    "                ,x.feature43\n",
    "                ,x.feature44\n",
    "                ,x.feature45\n",
    "                ,x.feature46\n",
    "                ,x.feature47\n",
    "                ,x.feature48\n",
    "                ,x.feature49\n",
    "                ,x.feature50\n",
    "                ]))).toDF([\"t_id\",\"features\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#(trainingData, testData) = train_df.randomSplit([0.6, 0.4],123456)\n",
    "(trainingData, testData,everythingElse) = train_df.randomSplit([0.2, 0.1, 0.7],12345)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define log loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import scipy as sp\n",
    "def logloss(act, pred):\n",
    "    epsilon = 1e-15\n",
    "    pred = sp.maximum(epsilon, pred)\n",
    "    pred = sp.minimum(1-epsilon, pred)\n",
    "    ll = sum(act*sp.log(pred) + sp.subtract(1,act)*sp.log(sp.subtract(1,pred)))\n",
    "    ll = ll * -1.0/len(act)\n",
    "    return ll"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Do PCA and rename REPLACE the features column\n",
    "\n",
    "pca = PCA(k=10, inputCol=\"features\", outputCol=\"pcaFeatures\")\n",
    "model = pca.fit(trainingData)\n",
    "trainingDataPCA = model.transform(trainingData).drop(\"features\")\n",
    "trainingDataPCA = trainingDataPCA.withColumn(\"features\",trainingDataPCA.pcaFeatures).drop(\"pcaFeatures\")\n",
    "\n",
    "testingDataPCA = model.transform(testData).drop(\"features\")\n",
    "testingDataPCA = testingDataPCA.withColumn(\"features\",testingDataPCA.pcaFeatures).drop(\"pcaFeatures\")\n",
    "\n",
    "tournamentDataPCA = model.transform(tournament_df).drop(\"features\")\n",
    "tournamentDataPCA = tournamentDataPCA.withColumn(\"features\",tournamentDataPCA.pcaFeatures).drop(\"pcaFeatures\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#same thing WITHOUT renaming/replacing the features column\n",
    "pca = PCA(k=10, inputCol=\"features\", outputCol=\"pcaFeatures\")\n",
    "model = pca.fit(trainingData)\n",
    "\n",
    "trainingDataPCA = model.transform(trainingData)\n",
    "testingDataPCA = model.transform(testData)\n",
    "tournamentDataPCA = model.transform(tournament_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#testingDataPCA.show(1,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trainingData = trainingDataPCA\n",
    "testData = testingDataPCA\n",
    "tournament_df =tournamentDataPCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "k=10\n",
    "#k=5\n",
    "#k=50\n",
    "threshold1=0.69\n",
    "threshold2=0.692"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "kmeans = KMeans().setK(k).setSeed(1)\n",
    "model = kmeans.fit(trainingData)\n",
    "wssse = model.computeCost(trainingData)\n",
    "print(\"Within Set Sum of Squared Errors = \" + str(wssse))\n",
    "centers = model.clusterCenters()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimise for the number of clusters by finding the inflection point in cost vs number of clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#for x in range(0, 100):\n",
    "#    kmeans = KMeans().setK(x).setSeed(1)\n",
    "#    model = kmeans.fit(trainingData)\n",
    "#    wssse = model.computeCost(trainingData)\n",
    "#    print(\"Within Set Sum of Squared Errors = \" + str(wssse))\n",
    "#    centers = model.clusterCenters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clustered_train_df = model.transform(trainingData)\n",
    "clustered_train_df = clustered_train_df.withColumn(\"clusterNum\",clustered_train_df.prediction).drop(\"prediction\")\n",
    "clustered_train_df.show(1)\n",
    "\n",
    "clustered_test_df = model.transform(testData)\n",
    "clustered_test_df = clustered_test_df.withColumn(\"clusterNum\",clustered_test_df.prediction).drop(\"prediction\")\n",
    "clustered_test_df.show(1)\n",
    "\n",
    "clustered_tournament_df = model.transform(tournament_df)\n",
    "clustered_tournament_df = clustered_tournament_df.withColumn(\"clusterNum\",clustered_tournament_df.prediction).drop(\"prediction\")\n",
    "clustered_tournament_df.show(1)\n",
    "\n",
    "\n",
    "clustered_test_df.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#clustered_train_df.show(1,False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Neural Net with Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "seed = 7\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#only do this to group all columns containing vectors into a single vector column\n",
    "assembler = VectorAssembler(\n",
    "    inputCols=[\"features\", \"clusterNum\",\"pcaFeatures\"],\n",
    "    outputCol=\"features2\")\n",
    "clustered_train_df2 = assembler.transform(clustered_train_df).drop('clusterNum').drop('features').drop(\"pcaFeatures\")\n",
    "clustered_test_df2  = assembler.transform(clustered_test_df).drop('clusterNum').drop('features').drop(\"pcaFeatures\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "assembler = VectorAssembler(\n",
    "    inputCols=[\"features\", \"clusterNum\"],\n",
    "    outputCol=\"features2\")\n",
    "clustered_train_df2 = assembler.transform(clustered_train_df)\n",
    "clustered_test_df2  = assembler.transform(clustered_test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#combine the different features columns with the k-means cluster output:\n",
    "\n",
    "assembler1 = VectorAssembler(\n",
    "    inputCols=[\"features\", \"clusterNum\"],\n",
    "    outputCol=\"features2\")\n",
    "clustered_train_df2 = assembler1.transform(clustered_train_df)\n",
    "clustered_test_df2  = assembler1.transform(clustered_test_df)\n",
    "\n",
    "\n",
    "assembler2 = VectorAssembler(\n",
    "    inputCols=[\"pcaFeatures\",\"clusterNum\"],\n",
    "    outputCol=\"pcafeatures2\")\n",
    "clustered_train_df2 = assembler2.transform(clustered_train_df2)\n",
    "clustered_test_df2  = assembler2.transform(clustered_test_df2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clustered_test_df2.show(1)\n",
    "clustered_test_df2.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features    = np.array(clustered_train_df2.select(\"features2\").toPandas())\n",
    "pcaFeatures = np.array(clustered_train_df2.select(\"pcaFeatures2\").toPandas())\n",
    "labels      = np.array(clustered_train_df2.select(\"label\").toPandas())\n",
    "\n",
    "featuresT    = np.array(clustered_test_df2.select(\"features2\").toPandas())\n",
    "labelsT      = np.array(clustered_test_df2.select(\"label\").toPandas())\n",
    "pcaFeaturesT = np.array(clustered_test_df2.select(\"pcaFeatures2\").toPandas())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features    = np.array(clustered_train_df2.select(\"features2\").toPandas())\n",
    "labels      = np.array(clustered_train_df2.select(\"label\").toPandas())\n",
    "\n",
    "featuresT    = np.array(clustered_test_df2.select(\"features2\").toPandas())\n",
    "labelsT      = np.array(clustered_test_df2.select(\"label\").toPandas())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#features    = np.array(trainingData.select(\"features\").toPandas())\n",
    "#pcaFeatures = np.array(trainingData.select(\"pcaFeatures\").toPandas())\n",
    "#labels      = np.array(trainingData.select(\"label\").toPandas())\n",
    "\n",
    "#featuresT    = np.array(testData.select(\"features\").toPandas())\n",
    "#labelsT      = np.array(testData.select(\"label\").toPandas())\n",
    "#pcaFeaturesT = np.array(testData.select(\"pcaFeatures\").toPandas())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#print features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features=clustered_train_df2.select(\"features2\").toPandas()\n",
    "labels  =clustered_train_df2.select(\"label\").toPandas()\n",
    "\n",
    "features = np.array(features)\n",
    "labels =   np.array(labels)\n",
    "\n",
    "featuresT =clustered_test_df2.select(\"features2\").toPandas()\n",
    "labelsT   =clustered_test_df2.select(\"label\").toPandas()\n",
    "\n",
    "featuresT = np.array(featuresT)\n",
    "labelsT = np.array(labelsT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_np     = np.array(map(lambda x: np.array(map(lambda y: np.array(y),x)), features))[:,][:][:]\n",
    "#train_np_pca = np.array(map(lambda x: np.array(map(lambda y: np.array(y),x)), pcaFeatures))[:,][:][:]\n",
    "train_res= np.array(map(lambda x: np.array(map(lambda y: np.array(y),x)), labels))[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_np_test     = np.array(map(lambda x: np.array(map(lambda y: np.array(y),x)), featuresT))[:,0][:][:]\n",
    "#train_np_pca_test = np.array(map(lambda x: np.array(map(lambda y: np.array(y),x)), pcaFeaturesT))[:,0][:][:]\n",
    "train_res_test    = np.array(map(lambda x: np.array(map(lambda y: np.array(y),x)), labelsT))[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print type(train_np[0])\n",
    "print train_np[10]\n",
    "\n",
    "print train_res[10]\n",
    "sum1= float(sum(train_res))\n",
    "len1= float(len(train_res))\n",
    "print \"ratio: \"+str(sum1/len1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print train_np.shape\n",
    "train_np=train_np.reshape(train_np.shape[0],train_np.shape[2])\n",
    "print train_np.shape\n",
    "\n",
    "#print train_np_pca.shape\n",
    "#train_np_pca=train_np_pca.reshape(train_np_pca.shape[0],train_np_pca.shape[2])\n",
    "#print train_np_pca.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(11, input_dim=11, init='uniform', activation='relu'))\n",
    "model.add(Dense(11, init='uniform', activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(11, init='uniform', activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(11, init='uniform', activation='relu'))\n",
    "#model.add(Dense(11, init='uniform', activation='relu', W_regularizer=l2(0.01)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(5, init='uniform', activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(1, init='uniform', activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "#model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "drop_out_rate=0.2\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "#model.add(Dropout(drop_out_rate, input_shape=(11,)))\n",
    "model.add(Dense(20, input_dim=11, init='uniform', activation='relu'))\n",
    "\n",
    "model.add(Dense(20, init='uniform', activation='relu'))\n",
    "#model.add(Dropout(drop_out_rate))\n",
    "model.add(Dense(400, init='uniform', activation='relu'))\n",
    "model.add(Dropout(0.9))\n",
    "#model.add(Dense(20, init='uniform', activation='relu'))\n",
    "#model.add(Dropout(drop_out_rate))\n",
    "#model.add(Dense(11, init='uniform', activation='relu', W_regularizer=l2(0.01)))\n",
    "#model.add(Dropout(drop_out_rate))\n",
    "#model.add(Dense(20, init='uniform', activation='relu'))\n",
    "#model.add(Dropout(drop_out_rate))\n",
    "#model.add(Dense(5, init='uniform', activation='relu'))\n",
    "\n",
    "model.add(Dense(1, init='uniform', activation='sigmoid'))\n",
    "\n",
    "#epochs = 200\n",
    "#learning_rate = 1\n",
    "#decay_rate = learning_rate / epochs\n",
    "#momentum = 0.1\n",
    "#sgd = SGD(lr=learning_rate, momentum=momentum, decay=decay_rate, nesterov=False)\n",
    "#model.compile(loss='binary_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_np, train_res, nb_epoch=epochs, batch_size=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#model.fit(train_np, train_res, nb_epoch=60, batch_size=1200)\n",
    "\n",
    "evaluated_train = model.evaluate(train_np,train_res)\n",
    "evaluated_test  = model.evaluate(train_np_test,train_res_test)\n",
    "\n",
    "nn_answer       = model.predict(train_np_test)\n",
    "\n",
    "print \"\"\n",
    "print \"---------------Train-------------------\"\n",
    "print \"logloss : \"+str(evaluated_train[0])\n",
    "print \"accuracy: \"+str(evaluated_train[1]*100)+\"%\"\n",
    "print \"---------------Test--------------------\"\n",
    "print \"logloss : \"+str(evaluated_test[0])\n",
    "print \"accuracy: \"+str(evaluated_test[1]*100)+\"%\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print nn_answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# XGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import xgboost\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = xgboost.XGBClassifier()\n",
    "\n",
    "#model.fit(train_np_pca, train_res)\n",
    "model.fit(train_np, train_res)\n",
    "\n",
    "# make predictions for test data\n",
    "#y_pred = model.predict(train_np_pca_test)\n",
    "y_pred = model.predict(train_np_test)\n",
    "\n",
    "xgb_predictions = [round(value) for value in y_pred]\n",
    "# evaluate predictions\n",
    "accuracy = accuracy_score(train_res_test, xgb_predictions)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print type(np.array(xgb_predictions))\n",
    "print type(nn_answer)\n",
    "\n",
    "nn_answer=nn_answer.reshape(nn_answer.shape[0],)\n",
    "\n",
    "print np.array(xgb_predictions)\n",
    "print nn_answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trainingData.show()\n",
    "\n",
    "train_xgb_udf = udf(lambda a: model.predict(a) , DoubleType())\n",
    "\n",
    "trainingData2=trainingData.withColumn(\"xgboost_pred\",train_xgb_udf(trainingData.features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_keras_udf = udf(lambda a,b: final_model. , DoubleType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainingData3=trainingData.withColumn(\"keras_pred\",train_keras_udf(trainingData.features,trainingData.pcaFeatures))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "evaluated  = final_model.predict([train_np_test,train_np_pca_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print evaluated.shape\n",
    "print train_res_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "evaluated=evaluated.reshape(evaluated.shape[0],)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "evaluated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_res_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ensemble = evaluated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#trainingData2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
