{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from pyspark.sql import *\n",
    "from pyspark import SparkConf,SparkContext\n",
    "sc=SparkContext()\n",
    "sqlContext=SQLContext(sc)\n",
    "import urllib\n",
    "from pyspark.sql.functions import UserDefinedFunction\n",
    "from pyspark.sql.types import StringType ,DoubleType ,BooleanType, IntegerType\n",
    "from pyspark.sql.functions import udf ,col ,upper, avg\n",
    "import numpy\n",
    "import math\n",
    "\n",
    "from pyspark.ml.regression import RandomForestRegressor\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "from pyspark.ml.classification import GBTClassifier\n",
    "from pyspark.ml.regression import GBTRegressor ,LinearRegression ,GeneralizedLinearRegression\n",
    "from pyspark.ml.feature import StringIndexer, VectorIndexer\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml.linalg import Vectors \n",
    "from pyspark.ml.linalg import VectorUDT\n",
    "\n",
    "from pyspark.ml.classification import MultilayerPerceptronClassifier\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "from pyspark.ml.clustering import KMeans\n",
    "from pyspark.ml.feature import PCA\n",
    "from pyspark.ml.linalg import Vectors\n",
    "\n",
    "\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import GBTClassifier\n",
    "from pyspark.ml.regression import GBTRegressor ,LinearRegression ,GeneralizedLinearRegression\n",
    "\n",
    "\n",
    "from pyspark.ml.feature import StringIndexer, VectorIndexer\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "#from pyspark.mllib.evaluation import RegressionMetrics\n",
    "\n",
    "\n",
    "from pyspark.ml.linalg import Vectors \n",
    "from pyspark.ml.linalg import VectorUDT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of training set:\n",
      "96320\n",
      "length of tournament set:\n",
      "135270\n"
     ]
    }
   ],
   "source": [
    "numerai_train_df     = sqlContext.read.option(\"header\",\"true\").csv('file:///home/garth/Downloads/numerai20161126/numerai_training_data.csv',inferSchema='true')\n",
    "numerai_tournament_df= sqlContext.read.option(\"header\",\"true\").csv('file:///home/garth/Downloads/numerai20161126/numerai_tournament_data.csv',inferSchema='true')\n",
    "\n",
    "print \"length of training set:\"\n",
    "print (numerai_train_df.count())\n",
    "print \"length of tournament set:\"\n",
    "print (numerai_tournament_df.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert input for use in ml lib algos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_df=numerai_train_df.rdd.map(lambda x: (float(x.target),Vectors.dense([\n",
    "                x.feature1\n",
    "                ,x.feature2\n",
    "                ,x.feature3\n",
    "                ,x.feature4\n",
    "                ,x.feature5\n",
    "                ,x.feature6\n",
    "                ,x.feature7\n",
    "                ,x.feature8\n",
    "                ,x.feature9\n",
    "                ,x.feature10\n",
    "                ,x.feature11\n",
    "                ,x.feature12\n",
    "                ,x.feature13\n",
    "                ,x.feature14\n",
    "                ,x.feature15\n",
    "                ,x.feature16\n",
    "                ,x.feature17\n",
    "                ,x.feature18\n",
    "                ,x.feature19\n",
    "                ,x.feature20\n",
    "                ,x.feature21\n",
    "                ]))).toDF([\"label\",\"features\"])\n",
    "\n",
    "tournament_df=numerai_tournament_df.rdd.map(lambda x: (x.t_id,Vectors.dense([\n",
    "                x.feature1\n",
    "                ,x.feature2\n",
    "                ,x.feature3\n",
    "                ,x.feature4\n",
    "                ,x.feature5\n",
    "                ,x.feature6\n",
    "                ,x.feature7\n",
    "                ,x.feature8\n",
    "                ,x.feature9\n",
    "                ,x.feature10\n",
    "                ,x.feature11\n",
    "                ,x.feature12\n",
    "                ,x.feature13\n",
    "                ,x.feature14\n",
    "                ,x.feature15\n",
    "                ,x.feature16\n",
    "                ,x.feature17\n",
    "                ,x.feature18\n",
    "                ,x.feature19\n",
    "                ,x.feature20\n",
    "                ,x.feature21\n",
    "                ]))).toDF([\"t_id\",\"features\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success rate of training set:\n",
      "0.505170265781\n"
     ]
    }
   ],
   "source": [
    "#print \"success rate of training set:\"\n",
    "#print str(float(train_df.where(\"label='1'\").count())/train_df.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Data for training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "(trainingData, testData) = train_df.randomSplit([0.7, 0.3],1234)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define log loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import scipy as sp\n",
    "def logloss(act, pred):\n",
    "    epsilon = 1e-15\n",
    "    pred = sp.maximum(epsilon, pred)\n",
    "    pred = sp.minimum(1-epsilon, pred)\n",
    "    ll = sum(act*sp.log(pred) + sp.subtract(1,act)*sp.log(sp.subtract(1,pred)))\n",
    "    ll = ll * -1.0/len(act)\n",
    "    return ll"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pca = PCA(k=21, inputCol=\"features\", outputCol=\"pcaFeatures\")\n",
    "model = pca.fit(trainingData)\n",
    "trainingDataPCA = model.transform(trainingData).drop(\"features\")\n",
    "trainingDataPCA = trainingDataPCA.withColumn(\"features\",trainingDataPCA.pcaFeatures).drop(\"pcaFeatures\")\n",
    "\n",
    "testingDataPCA = model.transform(testData).drop(\"features\")\n",
    "testingDataPCA = testingDataPCA.withColumn(\"features\",testingDataPCA.pcaFeatures).drop(\"pcaFeatures\")\n",
    "\n",
    "#testingDataPCA.show(2,False)\n",
    "#trainingDataPCA.show(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Perform Random Forest Regression on PCA features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "featureIndexer =\\\n",
    "    VectorIndexer(inputCol=\"features\", outputCol=\"indexedFeatures\", maxCategories=2).fit(trainingDataPCA)\n",
    "\n",
    "rf = RandomForestRegressor(featuresCol=\"indexedFeatures\")\n",
    "pipeline = Pipeline(stages=[featureIndexer, rf])\n",
    "model = pipeline.fit(trainingDataPCA)\n",
    "predictions_rfr = model.transform(testingDataPCA)\n",
    "training_rfr=model.transform(trainingDataPCA)\n",
    "#predictions_rfr.show(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy= 0.549694836727%\n",
      "percentage of 1s label :  0.503125881707%\n",
      "percentage of 1s predxn:  0.590323874014%\n",
      "logloss:\n",
      "0.68898841141\n",
      "__________________________________________________________________________________\n",
      "accuracy= 0.518375375272%\n",
      "percentage of 1s label :  0.509920977259%\n",
      "percentage of 1s predxn:  0.594706511612%\n",
      "logloss:\n",
      "0.691933340851\n"
     ]
    }
   ],
   "source": [
    "#print \"true  + :\" + str( predictions_rfr.where(\"label=='1.0' AND prediction > 0.5\").count() )\n",
    "#print \"false - :\" + str( predictions_rfr.where(\"label=='1.0' AND prediction < 0.5\").count() )\n",
    "#print \"false + :\" + str( predictions_rfr.where(\"label=='0.0' AND prediction > 0.5\").count() )\n",
    "#print \"true  - :\" + str( predictions_rfr.where(\"label=='0.0' AND prediction < 0.5\").count() )\n",
    "#print \"uncertain:\" + str (predictions_rfr.where(\"prediction=='0.5'\").count())\n",
    "#print (\"total count:\" + str(predictions_rfr.count()))\n",
    "#print \"\"\n",
    "\n",
    "print \"accuracy= \"+ str(float(training_rfr.where(\"(label=='1.0' AND prediction > 0.5) OR(label=='0.0' AND prediction < 0.5)\").count())/training_rfr.count()) +\"%\"\n",
    "print \"percentage of 1s label :  \"+ str(float(training_rfr.where(\"label==1.00\").count())/training_rfr.count()) +\"%\"\n",
    "print \"percentage of 1s predxn:  \"+ str(float(training_rfr.where(\"prediction>'.5'\").count())/training_rfr.count()) +\"%\"\n",
    "#training_rfr.describe().show()\n",
    "#print \"describe incorrect: \"\n",
    "#training_rfr.where(\"(label==0 and prediction>0.5) or (label==1 and prediction<0.5)\").describe().show()\n",
    "#print \"describe correct: \"\n",
    "#training_rfr.where(\"(label==1 and prediction>0.5) or (label==0 and prediction<0.5)\").describe().show()\n",
    "\n",
    "act=[float(i.label) for i in training_rfr.collect()]\n",
    "pred=[float(i.prediction) for i in training_rfr.collect()]\n",
    "print \"logloss:\" \n",
    "print logloss(act,pred)\n",
    "\n",
    "\n",
    "print \"__________________________________________________________________________________\"\n",
    "\n",
    "print \"accuracy= \"+ str(float(predictions_rfr.where(\"(label=='1.0' AND prediction > 0.5) OR(label=='0.0' AND prediction < 0.5)\").count())/predictions_rfr.count()) +\"%\"\n",
    "print \"percentage of 1s label :  \"+ str(float(predictions_rfr.where(\"label==1.00\").count())/predictions_rfr.count()) +\"%\"\n",
    "print \"percentage of 1s predxn:  \"+ str(float(predictions_rfr.where(\"prediction>'.5'\").count())/predictions_rfr.count()) +\"%\"\n",
    "#predictions_rfr.describe().show()\n",
    "#print \"describe incorrect: \"\n",
    "#predictions_rfr.where(\"(label==0 and prediction>0.5) or (label==1 and prediction<0.5)\").describe().show()\n",
    "#print \"describe correct: \"\n",
    "#predictions_rfr.where(\"(label==1 and prediction>0.5) or (label==0 and prediction<0.5)\").describe().show()\n",
    "\n",
    "act=[float(i.label) for i in predictions_rfr.collect()]\n",
    "pred=[float(i.prediction) for i in predictions_rfr.collect()]\n",
    "print \"logloss:\" \n",
    "print logloss(act,pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "percentage of very low in correct:  0.0%\n",
      "percentage of very low in incorrect:  0.0%\n",
      "logloss:\n",
      "0.691974302425\n"
     ]
    }
   ],
   "source": [
    "print \"percentage of very low in correct:  \"+ str(100*float(predictions_rfr.where(\"prediction<'.4' and label=0\").count())/predictions_rfr.count()) +\"%\"\n",
    "print \"percentage of very low in incorrect:  \"+ str(100*float(predictions_rfr.where(\"prediction<'.4' and label=1\").count())/predictions_rfr.count()) +\"%\"\n",
    "\n",
    "def improve(x):\n",
    "    if x < 0.47:\n",
    "        return (0.47)\n",
    "    else: return x\n",
    "    \n",
    "improve_answer_udf=udf(lambda x: improve(x), DoubleType())\n",
    "\n",
    "predictions_rfr=predictions_rfr.withColumn(\"prediction2\",improve_answer_udf(predictions_rfr.prediction)).drop(\"prediction\")\n",
    "predictions_rfr=predictions_rfr.withColumn(\"prediction\",predictions_rfr.prediction2).drop(\"prediction2\")\n",
    "act=[float(i.label) for i in predictions_rfr.collect()]\n",
    "pred=[float(i.prediction) for i in predictions_rfr.collect()]\n",
    "print \"logloss:\" \n",
    "print logloss(act,pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.405293488388\n",
      "0.490079022741\n",
      "0.518375375272\n"
     ]
    }
   ],
   "source": [
    "#Exploring answer:\n",
    "#predictions_rfr.show(2)\n",
    "print str(float(predictions_rfr.where(\"prediction<0.50\").count())/predictions_rfr.count())\n",
    "print str(float(predictions_rfr.where(\"label=0\").count())/predictions_rfr.count())\n",
    "print str(float(predictions_rfr.where(\"prediction<0.50 and label=0 OR (prediction>0.5 and label=1)\").count())/predictions_rfr.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform Generalised Linear Regression on PCA features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "glr = GeneralizedLinearRegression(family=\"gaussian\", link=\"identity\", maxIter=1000, regParam=0.3)\n",
    "model = glr.fit(trainingDataPCA)\n",
    "predictions_glr = model.transform(testingDataPCA)\n",
    "predictions_glr=predictions_glr.withColumnRenamed(\"prediction\",\"probability\")#.drop(\"features\")\n",
    "#predictions_glr.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "accuracy= 0.524690292971%\n",
      "logloss:\n",
      "0.691567438542\n"
     ]
    }
   ],
   "source": [
    "#print \"true  + :\" + str( predictions_glr.where(\"label=='1.0' AND prediction > 0.5\").count() )\n",
    "#print \"false - :\" + str( predictions_glr.where(\"label=='1.0' AND prediction < 0.5\").count() )\n",
    "#print \"false + :\" + str( predictions_glr.where(\"label=='0.0' AND prediction > 0.5\").count() )\n",
    "#print \"true  - :\" + str( predictions_glr.where(\"label=='0.0' AND prediction < 0.5\").count() )\n",
    "#print \"uncertain:\" + str (predictions_glr.where(\"prediction=='0.5'\").count())\n",
    "#print (\"total count:\" + str(predictions_glr.count()))\n",
    "print \"\"\n",
    "print \"accuracy= \"+ str(float(predictions_glr.where(\"(label=='1.0' AND prediction > 0.5) OR(label=='0.0' AND prediction < 0.5)\").count())/predictions_glr.count()) +\"%\"\n",
    "\n",
    "act=[float(i.label) for i in predictions_glr.collect()]\n",
    "pred=[float(i.probability) for i in predictions_glr.collect()]\n",
    "print \"logloss:\" \n",
    "print logloss(act,pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy= 52.137754926%\n",
      "logloss:\n",
      "0.695770143827\n",
      "+-----+--------------------+--------------------+------------------+\n",
      "|label|            features|     indexedFeatures|        prediction|\n",
      "+-----+--------------------+--------------------+------------------+\n",
      "|  0.0|[-0.8712915406536...|[-0.8712915406536...|0.5180750502233212|\n",
      "+-----+--------------------+--------------------+------------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gbt = GBTRegressor(featuresCol=\"indexedFeatures\", maxIter=20)\n",
    "pipeline = Pipeline(stages=[featureIndexer, gbt])\n",
    "model = pipeline.fit(trainingDataPCA)\n",
    "predictions_xgbtr = model.transform(testingDataPCA)\n",
    "\n",
    "print \"accuracy= \"+ str(float(100*predictions_xgbtr.where(\"(label=='1.0' AND prediction > 0.5) OR(label=='0.0' AND prediction < 0.5)\").count())/predictions_xgbtr.count()) +\"%\"\n",
    "act=[float(i.label) for i in predictions_xgbtr.collect()]\n",
    "pred=[float(i.prediction) for i in predictions_xgbtr.collect()]\n",
    "print \"logloss:\" \n",
    "print logloss(act,pred)\n",
    "predictions_xgbtr.show(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLPC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features length\n",
      "21\n",
      "28979\n",
      "Accuracy: 0.524966354947\n"
     ]
    }
   ],
   "source": [
    "print \"features length\"\n",
    "print (len(trainingDataPCA.first()['features']))\n",
    "layers = [21,25,2]\n",
    "trainer = MultilayerPerceptronClassifier(maxIter=2000, layers=layers, blockSize=128, seed=15)\n",
    "model = trainer.fit(trainingDataPCA)\n",
    "\n",
    "# compute accuracy on the test set\n",
    "predictions_MLPC = model.transform(testingDataPCA)\n",
    "print predictions_MLPC.count()\n",
    "predictionAndLabels = predictions_MLPC.select(\"prediction\", \"label\")\n",
    "evaluator = MulticlassClassificationEvaluator(metricName=\"accuracy\")\n",
    "print(\"Accuracy: \" + str(evaluator.evaluate(predictionAndLabels)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17561\n",
      "11418\n"
     ]
    }
   ],
   "source": [
    "print predictions_MLPC.where(\"prediction=1\").count()\n",
    "print predictions_MLPC.where(\"prediction=0\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "percentage of 1 labels: 50.9920977259\n"
     ]
    }
   ],
   "source": [
    "print \"percentage of 1 labels: \"+str(100*float(testingDataPCA.where(\"label==1\").count())/testingDataPCA.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Join tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions_rfr.createOrReplaceTempView(\"predictions_rfr\")\n",
    "predictions_glr.createOrReplaceTempView(\"predictions_glr\")\n",
    "predictions_MLPC.createOrReplaceTempView(\"predictions_MLPC\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+--------------------+-------------------+-----+--------------------+-------------------+-----+--------------------+----------+\n",
      "|label|            features|     indexedFeatures|         prediction|label|            features|        probability|label|            features|prediction|\n",
      "+-----+--------------------+--------------------+-------------------+-----+--------------------+-------------------+-----+--------------------+----------+\n",
      "|  1.0|[-1.2685594350497...|[-1.2685594350497...|0.49783679493286714|  1.0|[-1.2685594350497...| 0.5017600762929864|  1.0|[-1.2685594350497...|       1.0|\n",
      "|  0.0|[-1.1412805205326...|[-1.1412805205326...| 0.5018745107502193|  0.0|[-1.1412805205326...|0.49895845187150023|  0.0|[-1.1412805205326...|       0.0|\n",
      "+-----+--------------------+--------------------+-------------------+-----+--------------------+-------------------+-----+--------------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sqlContext.sql(\n",
    "            \"select * \\\n",
    "                from predictions_rfr join predictions_glr \\\n",
    "                on predictions_rfr.features = predictions_glr.features \\\n",
    "                inner join predictions_MLPC \\\n",
    "                on predictions_MLPC.features = predictions_rfr.features limit 2\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+-------------------+-------------------+---------+\n",
      "|             feature|label|           rfr_pred|           glr_pred|mlpc_pred|\n",
      "+--------------------+-----+-------------------+-------------------+---------+\n",
      "|[-1.2685594350497...|  1.0|0.49783679493286714| 0.5017600762929864|      1.0|\n",
      "|[-1.1412805205326...|  0.0| 0.5018745107502193|0.49895845187150023|      0.0|\n",
      "|[-0.9796959768020...|  0.0|0.49673980959551906| 0.5033670463598825|      0.0|\n",
      "|[-0.7917442126579...|  0.0| 0.4907994115811835| 0.5091977003021579|      1.0|\n",
      "|[-0.7444916352099...|  1.0| 0.5226694863003838| 0.5140961628993246|      1.0|\n",
      "|[-0.7377009368928...|  0.0| 0.5290123633865724| 0.5339846974012757|      1.0|\n",
      "|[-0.7324081107176...|  1.0| 0.5317641762214111| 0.5151858849838031|      1.0|\n",
      "|[-0.6038519329776...|  1.0|  0.521207141729467| 0.5152043743996617|      1.0|\n",
      "|[-0.5839139149905...|  1.0| 0.5024739825811787| 0.5030375076810534|      1.0|\n",
      "|[-0.5447004925595...|  0.0| 0.4812560321128886| 0.4922794454450084|      0.0|\n",
      "|[-0.5402901756806...|  1.0| 0.5255769876237133| 0.5102750774864876|      1.0|\n",
      "|[-0.5330586231326...|  0.0| 0.5083007731690998| 0.5034193361511321|      1.0|\n",
      "|[-0.4950753722882...|  1.0| 0.5059352429133435| 0.5203835605024408|      1.0|\n",
      "|[-0.4877621856400...|  0.0| 0.5216505224954852| 0.5050355457380667|      1.0|\n",
      "|[-0.4778660240811...|  0.0| 0.5114996411871998|  0.507006428682718|      1.0|\n",
      "|[-0.4539145894256...|  1.0| 0.5206798729489446| 0.5342184715747097|      1.0|\n",
      "|[-0.4478516971973...|  0.0| 0.5126671918123137|  0.522270598412864|      1.0|\n",
      "|[-0.4187348641910...|  0.0| 0.5013197262700407| 0.5020902571417407|      1.0|\n",
      "|[-0.3864801717081...|  1.0|0.49723219510183175| 0.5049814633107561|      1.0|\n",
      "|[-0.3752971377863...|  0.0|0.47211957970921753| 0.4922965907377091|      0.0|\n",
      "+--------------------+-----+-------------------+-------------------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ensemble_df = sqlContext.sql(\n",
    "            \"select predictions_rfr.features as feature \\\n",
    "            ,predictions_rfr.label as label \\\n",
    "            ,predictions_rfr.prediction as rfr_pred \\\n",
    "            ,predictions_glr.probability as glr_pred \\\n",
    "            ,predictions_MLPC.prediction as mlpc_pred \\\n",
    "                from predictions_rfr join predictions_glr \\\n",
    "                on predictions_rfr.features = predictions_glr.features \\\n",
    "                inner join predictions_MLPC \\\n",
    "                on predictions_MLPC.features = predictions_rfr.features\")\n",
    "\n",
    "ensemble_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "percentage in agreement rfr and glr: 0.489595914283\n"
     ]
    }
   ],
   "source": [
    "print \"percentage in agreement rfr and glr: \"\\\n",
    "    +str(float(ensemble_df.where(\"rfr_pred>0.5 and glr_pred>0.5\").count())/ensemble_df.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "percentage in agreement rfr and mlpc: 0.494944615066\n"
     ]
    }
   ],
   "source": [
    "print \"percentage in agreement rfr and mlpc: \"\\\n",
    "    +str(float(ensemble_df.where(\"rfr_pred>0.5 and mlpc_pred>0.5\").count())/ensemble_df.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "percentage in agreement mlpc and glr: 0.54349701508\n"
     ]
    }
   ],
   "source": [
    "print \"percentage in agreement mlpc and glr: \"\\\n",
    "    +str(float(ensemble_df.where(\"glr_pred>0.5 and mlpc_pred>0.5\").count())/ensemble_df.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "percentage in agreement mlpc and glr and rfr: 0.464198212499\n"
     ]
    }
   ],
   "source": [
    "print \"percentage in agreement mlpc and glr and rfr: \"\\\n",
    "    +str(float(ensemble_df.where(\"glr_pred>0.5 and mlpc_pred>0.5 and rfr_pred>0.5\").count())/ensemble_df.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label average\n",
      "+------------------+\n",
      "|        avg(label)|\n",
      "+------------------+\n",
      "|0.5099209772593948|\n",
      "+------------------+\n",
      "\n",
      "+--------------------+-----+-------------------+------------------+---------+\n",
      "|             feature|label|           rfr_pred|          glr_pred|mlpc_pred|\n",
      "+--------------------+-----+-------------------+------------------+---------+\n",
      "|[-0.7444916352099...|  1.0| 0.5226694863003838|0.5140961628993246|      1.0|\n",
      "|[-0.7377009368928...|  0.0| 0.5290123633865724|0.5339846974012757|      1.0|\n",
      "|[-0.7324081107176...|  1.0| 0.5317641762214111|0.5151858849838031|      1.0|\n",
      "|[-0.6038519329776...|  1.0|  0.521207141729467|0.5152043743996617|      1.0|\n",
      "|[-0.5839139149905...|  1.0| 0.5024739825811787|0.5030375076810534|      1.0|\n",
      "|[-0.5447004925595...|  0.0| 0.4812560321128886|0.4922794454450084|      0.0|\n",
      "|[-0.5402901756806...|  1.0| 0.5255769876237133|0.5102750774864876|      1.0|\n",
      "|[-0.5330586231326...|  0.0| 0.5083007731690998|0.5034193361511321|      1.0|\n",
      "|[-0.4950753722882...|  1.0| 0.5059352429133435|0.5203835605024408|      1.0|\n",
      "|[-0.4877621856400...|  0.0| 0.5216505224954852|0.5050355457380667|      1.0|\n",
      "|[-0.4778660240811...|  0.0| 0.5114996411871998| 0.507006428682718|      1.0|\n",
      "|[-0.4539145894256...|  1.0| 0.5206798729489446|0.5342184715747097|      1.0|\n",
      "|[-0.4478516971973...|  0.0| 0.5126671918123137| 0.522270598412864|      1.0|\n",
      "|[-0.4187348641910...|  0.0| 0.5013197262700407|0.5020902571417407|      1.0|\n",
      "|[-0.3752971377863...|  0.0|0.47211957970921753|0.4922965907377091|      0.0|\n",
      "|[-0.3678751070452...|  1.0|  0.503155263842298|0.5011883486301852|      1.0|\n",
      "|[-0.3284009782985...|  0.0| 0.4845244218449542|0.4833958248565734|      0.0|\n",
      "|[-0.3157149784157...|  0.0| 0.5449673898933367|0.5314669678820756|      1.0|\n",
      "|[-0.2849697352227...|  1.0|0.48538885827495737|0.4899601225037378|      0.0|\n",
      "|[-0.2835167567504...|  0.0|0.48052574271065096|0.4691754934754707|      0.0|\n",
      "+--------------------+-----+-------------------+------------------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#print \"avg where they agree: \"\\\n",
    "#    +str(float(ensemble_df.where(\"glr_pred>0.5 and mlpc_pred>0.5 and rfr_pred>0.5\")))\n",
    "\n",
    "#print \"label average\"\n",
    "#ensemble_df.agg(avg(col(\"label\"))).show()\n",
    "\n",
    "#print \"glr and rfr average\"\n",
    "#ensemble_df.agg(avg(col(\"glr_pred\"))).show()\n",
    "#ensemble_df.agg(avg(col(\"rfr_pred\"))).show()\n",
    "\n",
    "#ensemble_df.where(\"(glr_pred>0.5 and mlpc_pred>0.5 and rfr_pred>0.5)\").agg(avg(col(\"glr_pred\"))).show()\n",
    "#ensemble_df.where(\"(glr_pred>0.5 and mlpc_pred>0.5 and rfr_pred>0.5)\").agg(avg(col(\"rfr_pred\"))).show()\n",
    "\n",
    "#ensemble_df.where(\"glr_pred<0.5 and mlpc_pred<0.5 and rfr_pred<0.5\").agg(avg(col(\"glr_pred\"))).show()\n",
    "#ensemble_df.where(\"glr_pred<0.5 and mlpc_pred<0.5 and rfr_pred<0.5\").agg(avg(col(\"rfr_pred\"))).show()\n",
    "\n",
    "#print \"average where rfr,flr and mlpc models agree\"\n",
    "#ensemble_df.where(\"(glr_pred>0.5 and mlpc_pred>0.5 and rfr_pred>0.5) or (glr_pred<0.5 and mlpc_pred<0.5 and rfr_pred<0.5)\").agg(avg(col(\"glr_pred\"))).show()\n",
    "#ensemble_df.where(\"(glr_pred>0.5 and mlpc_pred>0.5 and rfr_pred>0.5) or (glr_pred<0.5 and mlpc_pred<0.5 and rfr_pred<0.5)\").agg(avg(col(\"rfr_pred\"))).show()    \n",
    "\n",
    "models_agree_df=ensemble_df.where(\"(glr_pred>0.5 and mlpc_pred>0.5 and rfr_pred>0.5) \\\n",
    "                                or (glr_pred<0.5 and mlpc_pred<0.5 and rfr_pred<0.5)\")    \n",
    "models_agree_df.show()\n",
    "#model_disagree_df=ensemble_df.where(\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logloss:\n",
      "0.691125313353\n",
      "+-----+--------------------+--------------------+------------------+\n",
      "|label|            features|     indexedFeatures|        prediction|\n",
      "+-----+--------------------+--------------------+------------------+\n",
      "|  0.0|[-0.8712915406536...|[-0.8712915406536...|0.5180750502233212|\n",
      "+-----+--------------------+--------------------+------------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "models_agree_df=models_agree_df.withColumn(\"prediction\",(models_agree_df.rfr_pred+models_agree_df.glr_pred)/2)\n",
    "\n",
    "act=[float(i.label) for i in models_agree_df.collect()]\n",
    "pred=[float(i.prediction) for i in models_agree_df.collect()]\n",
    "print \"logloss:\" \n",
    "print logloss(act,pred)\n",
    "predictions_xgbtr.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
